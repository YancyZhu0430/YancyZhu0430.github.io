---
title: "Research Interests and Industrial Collaborations"
collection: research
type: "research"
permalink: /research/2012-03-01-talk-1
---





## **Research Interests**

##### Safe Reinforcement Learning (RL) in Future Energy System Dispatch and Control

Most of RL algorithm does not 100 % guarantee the fulfillment of constraints. This is unacceptable for dispatch and control tasks, as the violation of constraints is extremely harmful. The emerging Safe RL is a promising solution to tackle this problem. With safe RL, conventional RL algorithms (such as TRPO, PPO, SAC) with outstanding computational performance can be tailored to fulfill the security requirements of dispatching and control tasks. The well-trained smart agent can achieve online and real-time optimal decision-making, with much faster computation speed than mathematical-programming-based optimization methods. As potential applications, this methodology can be deployed to the dispatch and control of microgrid clusters, virtual power plants, multi-energy systems, smart buildings/energy hubs in future smart cities, etc. 

*We are also interested in how to deploy machine learning techniques to accelerate conventional optimization methodologies, as a complementary and more conservative approach in comparison with RL-based methods.*

**Imitation Learning in Future Energy System Dispatch and Control** 

Imitation learning can be considered as the combination of RL and Generative Adversarial Networks (GAN). It enables the smart agent to learn from the existing ”expert dataset”, rather than interaction with the environment. Hence, it is perfectly suitable to tasks that 1) cost painfully if it fails, i.e., it is difficult to develop a model for the agent to interact with; and 2) requires fast response speed. Potential applications may include the power system dispatch/control under contingency issues. By using expert dataset generated by human dispatchers with outstanding working experience, the imitation learning can be helpful to achieve fast online dispatch under power system faults, which will be frequently encountered in face of high renewable penetration and extreme weathers. 

**Data-Driven Macro-Level Energy Policies Analysis**

RL is a bottom-up, agent-based simulation tool, which requires very accurate modeling of the environment. Hence, it is only applicable to small-scale systems, such as local electricity markets. For analysis of Macro energy policies in large systems (for example, in regional-level or cross-national energy markets), detailed modeling of the environment is overwhelmingly complicated. Existing solutions are those ”top-down” models, such as General Equilibrium Models and Econometrics Models. However, top-down models cannot formulate the bottom-level behaviors well. An intuitive idea is to combine Top-down models and RL, with their advantages combined together. This methodology can be used to investigate many interesting topics related to marco-level energy policy analysis.



## Industrial Projects and Collaborations

We will be collaborating with *HK Electric Co.Ltd* (香港電燈有限公司), aiming at developing an AI-enabled power system asset management, monitoring and maintenance system. Key topics under this research project include:

1. Advanced Deep Learning Techniques for Fault diagnosis;
2. Advanced Deep Learning Techniques for Asset Monitoring and Maintenance;
3. Statistical Load Forecasting;

*Details to be confirmed soon...*
